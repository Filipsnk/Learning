# -*- coding: utf-8 -*-
"""
Created on Fri Sep 13 08:05:09 2019

@author: Filip.Fraczek
"""

Created on Thu Sep 12 17:51:09 2019
@author: filipfraczek


import pandas as pd
import numpy as np

r_cols = ['user_id', 'movie_id', 'rating']
ratings = pd.read_csv('u.data', sep='\t', names=r_cols, usecols=range(3), encoding="ISO-8859-1")

m_cols = ['movie_id', 'title']
movies = pd.read_csv('u.item', sep='|', names=m_cols, usecols=range(2), encoding="ISO-8859-1")
ratings = pd.merge(movies, ratings)

userRatings = ratings.pivot_table(index=['user_id'],columns=['title'],values='rating')
userRatings.head()

corrMatrix = userRatings.corr(method='pearson', min_periods=100)
corrMatrix.head()

tabela = pd.DataFrame({'A':[1,2,3,4],
                       'B':[1,2,4,3],
                       'C':[4,3,2,1]})
tabela[::-2]
tabela
#How many missing values


X = pd.DataFrame(columns = ['columns','missing'])

for i in range(0,len(userRatings.index)):
    column = userRatings.index[i]
    missing = userRatings.loc[i].isnull().sum()
    X = X.append({'columns': column, 'missing':missing},ignore_index = True)
    
X.sort_values(by='missing', ascending = True)

#test
"""
sims= corrMatrix[myRatings.index[0]].dropna()
sims= sims.map(lambda x: x * myRatings[0])
simCandidates = simCandidates.append(sims)
sims= corrMatrix[myRatings.index[1]].dropna()
sims= sims.map(lambda x: x * myRatings[1])
simCandidates = simCandidates.append(sims)
sims = corrMatrix[myRatings.index[2]].dropna()
sims = sims.map(lambda x: x * myRatings[2])
simCandidates = simCandidates.append(sims)
"""

# Start petli


final_matrix = pd.DataFrame(columns=['Id','movie1','movie2','movie3'])

userRatings2 = userRatings.iloc[:100,]


for i in range(0,len(userRatings2.index)): 

    myRatings = userRatings2.loc[i].dropna()
    
    simCandidates = pd.Series()
    for j in range(0, len(myRatings.index)):
        print ("Adding sims for " + myRatings.index[j] + "...")
        # Retrieve similar movies to this one that I rated
        sims = corrMatrix[myRatings.index[j]].dropna()
        # Now scale its similarity by how well I rated this movie
        sims = sims.map(lambda x: x * myRatings[j])
        # Add the score to the list of similarity candidates
        simCandidates = simCandidates.append(sims)
        
    print ("sorting...")
    simCandidates.sort_values(inplace = True, ascending = False)
              
    simCandidates = simCandidates.groupby(simCandidates.index).sum()
            
    simCandidates.sort_values(inplace = True, ascending = False)
    
    for z in simCandidates.index:
        if z in myRatings.index:
            simCandidates = simCandidates.drop(index = z)
            
    #filteredSims = simCandidates.drop(myRatings.index, inplace = True)
            
    top_recommendations = simCandidates.nlargest(3)
    top = top_recommendations.index
    top = pd.Series(top)
    
    final_matrix = final_matrix.append({'Id': userRatings2.index[i],'movie1':top[0], 'movie2':top[1],'movie3':top[2]},ignore_index = True)
    
    
###################### test

from surprise import KNNWithMeans
from surprise import Dataset
from surprise import Reader

from surprise import SVD
from surprise import Dataset
from surprise.model_selection import cross_validate


# Load the movielens-100k dataset (download it if needed),
data = Dataset.load_builtin('ml-100k')

# We'll use the famous SVD algorithm.
algo = SVD()

# Run 5-fold cross-validation and print results
cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)

from geopy import GoogleV3

place = "221b Baker Street, London"
location = GoogleV3().geocode(place)


# To use item-based cosine similarity
sim_options = {
    "name": "cosine",
    "user_based": False,  # Compute  similarities between items
}
algo = KNNWithMeans(sim_options=sim_options)

ratings_dict = {
    "item": [1, 2, 1, 2, 1, 2, 1, 2, 1],
    "user": ['A', 'A', 'B', 'B', 'C', 'C', 'D', 'D', 'E'],
    "rating": [1, 2, 2, 4, 2.5, 4, 4.5, 5, 3],
}

df = pd.DataFrame(ratings_dict)
reader = Reader(rating_scale=(1, 5))

from geopy import GoogleV3



myRatings = userRatings2.loc[i].dropna()
    
    simCandidates = pd.Series()
    for j in range(0, len(myRatings.index)):
        print ("Adding sims for " + myRatings.index[j] + "...")
        # Retrieve similar movies to this one that I rated
        sims = corrMatrix[myRatings.index[j]].dropna()
        # Now scale its similarity by how well I rated this movie
        sims = sims.map(lambda x: x * myRatings[j])
        # Add the score to the list of similarity candidates
        simCandidates = simCandidates.append(sims)
        
    print ("sorting...")
    simCandidates.sort_values(inplace = True, ascending = False)
              
    simCandidates = simCandidates.groupby(simCandidates.index).sum()
            
    simCandidates.sort_values(inplace = True, ascending = False)
    
    for z in simCandidates.index:
        if z in myRatings.index:
            simCandidates = simCandidates.drop(index = z)
            
    #filteredSims = simCandidates.drop(myRatings.index, inplace = True)
            
    top_recommendations = simCandidates.nlargest(3)
    top = top_recommendations.index
    top = pd.Series(top)
    
    final_matrix = final_matrix.append({'Id': userRatings2.index[i],'movie1':top[0], 'movie2':top[1],'movie3':top[2]},ignore_index = True)
    














































